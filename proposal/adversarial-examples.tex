\section{Adversarial Examples}\label{adversary}
\paragraph{}
The authors of the main paper say the proposed neural network could be less susceptible to adversarial examples, but without justification or experiments to corroborate.

We propose to objectively verify this intuition. A simple method for generating adversarial examples is given by \cite{goodfellow2014explaining}, we can use it to generate a set of adversarial examples for the datasets and then compare how each model performs.

A more ambitious approach, again time-permitting, would be trying to replicate what \cite{fischetti2017deep} did for Neural Networks with ReLUs as activation functions, adapting their program to hard-threshold activation functions